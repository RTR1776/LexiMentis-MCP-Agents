$schema: ../schema/mcp-agent.config.schema.json

execution_engine: asyncio
logger:
  type: console
  level: info
  batch_size: 100
  flush_interval: 2
  max_queue_size: 2048

mcp:
  servers:
    neon_vector:
      # Neon Vector Database server
      command: "uvx"
      args: [
          "mcp-server-postgres", # Assuming you'll use the postgres connector
          "--connection-string",
          "postgresql://user:password@your-neon-db-host/dbname", # Update with your Neon connection string
          "--vector-table",
          "your_embeddings_table", # Your table with embeddings
          "--embedding-model",
          "BAAI/bge-small-en-v1.5", # Or your preferred embedding model
        ]
      # For web clients, enable SSE transport
      transport: "sse"
      url: "http://localhost:8000/sse" # The URL where your server will expose the SSE endpoint

# Add your preferred LLM configuration
openai:
  # Secrets (API keys, etc.) should be stored in mcp_agent.secrets.yaml which can be gitignored
  default_model: gpt-4o
# Uncomment if using Anthropic models
# anthropic:
#   default_model: claude-3-opus-20240229
